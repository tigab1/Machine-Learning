{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import Lasso, LinearRegression, SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from yellowbrick.model_selection import ValidationCurve\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yellowbrick\n",
      "  Using cached yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from yellowbrick) (1.4.1)\n",
      "Requirement already satisfied: cycler>=0.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from yellowbrick) (0.10.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from yellowbrick) (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from yellowbrick) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from yellowbrick) (1.0.2)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cycler>=0.10.0->yellowbrick) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.4.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->yellowbrick) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->yellowbrick) (0.14.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (45.2.0.post20200210)\n",
      "Installing collected packages: yellowbrick\n",
      "Successfully installed yellowbrick-1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "DATA_FOLDER = 'data/'\n",
    "GRAPH_FOLDER = 'graphs/'\n",
    "RANDOM_STATE = 0\n",
    "TEST_SIZE = 0.2\n",
    "K_FOLD_SETTINGS = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom score function\n",
    "def score_f1(y_true, y_pred, threshold):\n",
    "    return f1_score(y_true=y_true>threshold, y_pred=y_pred>threshold)\n",
    "\n",
    "def score_regression(y_true, y_pred):\n",
    "    scores = [score_f1(y_true, y_pred, th) for th in [500, 1400, 5000, 10000]]\n",
    "    return np.mean(scores)\n",
    "\n",
    "# [See](https://stackoverflow.com/questions/32401493/how-to-create-customize-your-own-scorer-function-in-scikit-learn)\n",
    "reg_scorer = make_scorer(score_regression, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_FOLDER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-071512ee1fe2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_FOLDER\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[1;34m'X1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mY1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_FOLDER\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Y1.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shares'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Make a copy of data to work with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_FOLDER' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the data\n",
    "X1 = pd.read_csv(DATA_FOLDER +  'X1.csv')\n",
    "Y1 = pd.read_csv(DATA_FOLDER + 'Y1.csv', header=None, names=['shares'])\n",
    "\n",
    "# Make a copy of data to work with\n",
    "df = X1.copy()\n",
    "target = Y1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data into train/test --> 80%/20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print('X_train:', X_train.shape, 'y_train:', y_train.shape)\n",
    "print('X_test:\\t', X_test.shape, ' y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y_train['shares'].values, y_test['shares'].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(X, y, models):\n",
    "    out = {}\n",
    "    for label, model in models.items():\n",
    "        m = model.fit(X, y)\n",
    "        p = m.predict(X)\n",
    "        out[label] = [np.round(score_regression(y, p), 3)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of models to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to be estimated\n",
    "models = {\n",
    "    'OLS': LinearRegression(),     \n",
    "    'SGDR': SGDRegressor(\n",
    "        loss='huber',\n",
    "        penalty='l2',\n",
    "        max_iter=1000,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),    \n",
    "    'Lasso': Lasso(\n",
    "        random_state=RANDOM_STATE\n",
    "    ),    \n",
    "    'KNN': KNeighborsRegressor(n_jobs=-1),    \n",
    "    'MLP': MLPRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_iter = 2000\n",
    "    ),     \n",
    "    'RF': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        criterion='mse', n_jobs=-1,\n",
    "        random_state = RANDOM_STATE\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models on raw data\n",
    "out = fit_models(X_train, y_train, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(out, index=['On raw data'])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from the book -Hands-On Machine Learning with Scikit-Learn and TensorFlow by Aurélien Géron-\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.feature_names].values       \n",
    "        \n",
    "\n",
    "# Define custom log transformer for some unbounded numerical variables\n",
    "\n",
    "class LogTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.log( X + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define set of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of columns to pre-process\n",
    "links_features = ['num_hrefs', 'num_self_hrefs',  'self_reference_min_shares',\n",
    "                  'self_reference_avg_sharess', 'self_reference_max_shares']\n",
    "# digital media features\n",
    "dm_features = ['num_imgs', 'num_videos']\n",
    "\n",
    "cols_log_transform = ['n_tokens_content', 'average_token_length'] + links_features + dm_features + ['num_keywords']\n",
    "\n",
    "def is_bool_feature(colname):\n",
    "    if colname.startswith('weekday_is_'):\n",
    "        return True\n",
    "    if colname.startswith('data_channel_is_'):\n",
    "        return True\n",
    "    if colname.startswith('is_weekend'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Boolean features\n",
    "bool_features = [colname for colname in X_train.columns if is_bool_feature(colname)]\n",
    "# Other numerical features\n",
    "float_features = [colname for colname in X_train.columns if colname not in bool_features]\n",
    "# features that will not be Log-transformed and are not boolean\n",
    "cols_not_to_log_trans_not_bool = [colname for colname in X_train.columns if\\\n",
    "                                  (colname not in cols_log_transform) and (colname not in bool_features)]\n",
    "\n",
    "# print(len(cols_log_transform) + len(cols_not_to_log_trans_not_bool) + len(bool_features))\n",
    "# print(len(bool_features) + len(float_features))\n",
    "# print(len(X_train.columns))\n",
    "\n",
    "all_cols = cols_log_transform + cols_not_to_log_trans_not_bool + bool_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define pipeline for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform pipeline\n",
    "lt_pipe = Pipeline(steps = [\n",
    "    ('log_selector', FeatureSelector(feature_names=cols_log_transform)),\n",
    "    ('log_transformer', LogTransformer()),\n",
    "    ('log_std_scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline(steps = [\n",
    "    ('num_selector', FeatureSelector(feature_names=cols_not_to_log_trans_not_bool)),\n",
    "    ('num_std_scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "bool_pipe = Pipeline(steps= [\n",
    "    ('bool_selector', FeatureSelector(feature_names=bool_features))\n",
    "])\n",
    "\n",
    "preprocessor = FeatureUnion(transformer_list = [\n",
    "    ('lt_pipe', lt_pipe),\n",
    "    ('num_pipe', num_pipe),\n",
    "    ('bool_pipe', bool_pipe)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data and reassign the column names\n",
    "X_train_pp = preprocessor.fit_transform(X_train)\n",
    "X_train_pp = pd.DataFrame(X_train_pp, columns=all_cols)\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_train_pp:', X_train_pp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models on pre-processed data\n",
    "out = fit_models(X_train_pp, y_train, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.concat([scores, pd.DataFrame(out, index=['On processed data'])], axis=0)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models_cv(X, y, models, cv=5):\n",
    "    n_cv = cv.n_splits if isinstance(cv, KFold) else cv\n",
    "    rows = ['Training']*n_cv + ['Validation']*n_cv\n",
    "    out = pd.DataFrame({'Set': rows}, index=rows)\n",
    "    for label, model in models.items():\n",
    "        cv_scores = cross_validate(\n",
    "            estimator=model, X=X, y=y,\n",
    "            scoring = reg_scorer,\n",
    "            cv = K_FOLD_SETTINGS,\n",
    "            return_train_score = True, n_jobs=4\n",
    "        )\n",
    "        values = np.append(cv_scores['train_score'], cv_scores['test_score'], axis=0)\n",
    "        temp = pd.DataFrame({label: np.round(values, 3)}, index=rows)\n",
    "        out = pd.concat([out, temp], axis=1)\n",
    "    return pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models using Cross-Validation\n",
    "cv_scores = fit_models_cv(X=X_train_pp, y=y_train, models=models, cv=K_FOLD_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores.groupby('Set').mean().transpose().plot(kind='barh', title='Training and validation scores');\n",
    "plt.savefig(GRAPH_FOLDER +  'scores_train_val.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print( cv_scores.groupby('Set').mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get the learning curves of all estimators\n",
    "def learning_curves_models(X, y, models, train_sizes, cv, random_state=0):\n",
    "    n = len(models)\n",
    "    cols = 2\n",
    "    rows = int(np.ceil( n / cols ))\n",
    "    i = 1\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for label, estimator in models.items():\n",
    "        lcrv = learning_curve(\n",
    "            estimator=estimator, X=X, y=y, train_sizes=train_sizes, \n",
    "            cv=cv, scoring=reg_scorer, random_state=random_state, n_jobs=-1, \n",
    "        )\n",
    "        ts, train_scores, val_scores = lcrv\n",
    "        train_scores, val_scores = 1 - train_scores, 1 - val_scores\n",
    "        \n",
    "        plt.subplot(rows, cols, i)\n",
    "        plt.plot(ts, train_scores.mean(1), c='r', label=\"Training error\")\n",
    "        plt.plot(ts, val_scores.mean(1), c='g', label=\"Cross validation error\")\n",
    "        plt.title(f'Learning curve {label}')\n",
    "        if i in [n-1, n]:\n",
    "            plt.xlabel('Training examples')\n",
    "        plt.legend(loc=\"best\")\n",
    "        \n",
    "        i += 1\n",
    "    plt.savefig(GRAPH_FOLDER + 'learning_curves.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Learning curves of all the models\n",
    "learning_curves_models(\n",
    "    X_train_pp, y_train, models, np.linspace(0.01, 1, 10), \n",
    "    K_FOLD_SETTINGS, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Variable selection using Random Forest feature importance\n",
    "rf = RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf.fit(X_train_pp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(rf.feature_importances_, index = X_train_pp.columns)\n",
    "feat_importances.nlargest(X_train_pp.shape[1]).sort_values().plot(\n",
    "    kind='barh', title='Feature importance',figsize=(8,12)\n",
    ")\n",
    "plt.savefig(GRAPH_FOLDER + 'feature_selection_rf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using mutual information\n",
    "mir = mutual_info_regression(\n",
    "    X=X_train_pp, y=y_train, \n",
    "    discrete_features='auto', n_neighbors=5,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = pd.Series(mir, index=X_train_pp.columns)\n",
    "mutual_info.sort_values( ascending=True).plot(\n",
    "    kind='barh', title='Mutual information', figsize=(8,12)\n",
    ")\n",
    "plt.savefig(GRAPH_FOLDER + 'feature_selection_mir.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the common variable among the 1st 40 select by both rf and mir\n",
    "number_to_select = 45\n",
    "m = mutual_info.sort_values(ascending=False).index[:number_to_select]\n",
    "r = feat_importances.sort_values(ascending=False).index[:number_to_select]\n",
    "\n",
    "selected_features = list(set(m).intersection(set(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel = X_train_pp[selected_features]\n",
    "X_train_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest and KNN\n",
    "selected_models = {\n",
    "    'KNN': models['KNN'],    \n",
    "    'RF': models['RF']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation curve function\n",
    "\n",
    "def validation_curve(X, y, model, param_name, param_range, cv):\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    rf_vc = ValidationCurve(\n",
    "        model, param_name=param_name, scoring=reg_scorer,\n",
    "        param_range=param_range, cv=cv, n_jobs=-1\n",
    "    )\n",
    "    rf_vc.fit(X_train, y_train)\n",
    "    rf_vc.poof()\n",
    "    fname = model.__class__.__name__.lower()\n",
    "    fig.savefig(GRAPH_FOLDER + f\"{fname}_vc_{param_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation curves for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest validation curve for max_depth\n",
    "validation_curve(\n",
    "    X_train_sel, y_train, \n",
    "    selected_models['RF'], 'max_depth', \n",
    "    np.arange(1,40,3), K_FOLD_SETTINGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest validation curve for n_estimators\n",
    "validation_curve(\n",
    "    X_train_sel, y_train, selected_models['RF'], \n",
    "    'n_estimators', [100, 200, 300, 500], K_FOLD_SETTINGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest validation curve for max_features\n",
    "validation_curve(\n",
    "    X_train_sel, y_train, selected_models['RF'], \n",
    "    'max_features', [1, 2, 3, 5, 7, 11, 13, 17], K_FOLD_SETTINGS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation curves for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN validation curve for n_neighbors\n",
    "validation_curve(\n",
    "    X_train_sel, y_train, selected_models['KNN'], \n",
    "    'n_neighbors', [1, 3, 5, 7, 11, 13, 17, 19, 29], K_FOLD_SETTINGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_curve(\n",
    "    X_train_pp, y_train, selected_models['KNN'], \n",
    "    'weights', ['uniform', 'distance'], K_FOLD_SETTINGS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize  RandomForestRegressor, using the GridSearchCV\n",
    "\n",
    "rf_grid_params = [\n",
    "    {'n_estimators': [150, 200, 300], \n",
    "     'max_depth': [20, 23, 25, 30],\n",
    "    },\n",
    "]\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    selected_models['RF'], rf_grid_params, \n",
    "    cv=K_FOLD_SETTINGS, scoring=reg_scorer, n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "rf_grid_search.fit(X_train_pp[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_estimator = rf_grid_search.best_estimator_\n",
    "rf_best_score = rf_grid_search.best_score_\n",
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize KNN, using the GridSearchCV\n",
    "\n",
    "knn_grid_params = [\n",
    "    {'n_neighbors': [3, 5, 7, 9, 11, 13], \n",
    "     'metric': ['minkowski', 'mahalanobis', 'seuclidean'],\n",
    "     'algorithm': ['ball_tree', 'kd_tree']\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_grid_search = GridSearchCV(\n",
    "    selected_models['KNN'], knn_grid_params, cv=K_FOLD_SETTINGS, \n",
    "    scoring=reg_scorer, n_jobs=-1, return_train_score=True\n",
    ")\n",
    "\n",
    "knn_grid_search.fit(X_train_pp[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_estimator = knn_grid_search.best_estimator_\n",
    "knn_best_score = knn_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = None\n",
    "if rf_best_score >= knn_best_score:\n",
    "    final_model = rf_best_estimator\n",
    "else:\n",
    "    final_model = knn_best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the final model on the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(X_train_pp[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_predictions(X_test, y_test, model, preprocessor=None, selected_features=None):\n",
    "    # Prepare the data\n",
    "    X_test_pp = preprocessor.transform(X_test) if preprocessor is not None else X_test\n",
    "    X_test_pp = pd.DataFrame(X_test_pp, columns=X_test.columns)\n",
    "    # Predictions\n",
    "    X = X_test_pp if selected_features is None else X_test_pp[selected_features]\n",
    "    predictions = model.predict(X)\n",
    "    # Score\n",
    "    score = score_regression(y_test, predictions)\n",
    "    return np.round(score * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_score = final_predictions(\n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    model=final_model, \n",
    "    preprocessor=preprocessor, \n",
    "    selected_features=selected_features\n",
    ")\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.read_csv(DATA_FOLDER + 'X2.csv')\n",
    "\n",
    "# Pre-process X2\n",
    "X2_pp = preprocessor.transform(X2)\n",
    "X2_pp = pd.DataFrame(X2_pp, columns=all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = final_model.predict(X2_pp[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions\n",
    "pd.DataFrame(Y2).to_csv('Y2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total running time:', t1-t0)\n",
    "(t1-t0)/60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
